Il numero di spostamenti per la torre di hanoi è uguale a 2(numero spostamenti -1)+1
Questo è quindi uguale a NS(N)=(2^n)-1. Questo tipo di equazioni vengono chiamate equazioni di ricorrenza
La precedente equazioni può dimostrarsi tramite principio di induzione-->
NS(K)=2^k -1
NS(K+1)=2 NS(K)+1==>2(2^K-1)+1==>(2^K+1)-2+1==>(2^K+1)-1

Per convenzione la nostra unità di tempo sarà uguale ad un'unità di riga di
codice semplice(senza cicli e chiamate a varie funzioni)
Complessità di un algoritmo, intendiamo la complessità nel caso peggiore

Nel caso di un if la complessità dell'algoritmo è dato dal:
costo(guardia)+(max(costo(blocco1),costo(blocco2))), dove con guardia intendiamo
la condizione, blocco1 l'istruzione dopo l'if e blocco2 l'istruzione dell'else.
Se il costo del primo blocco fosse 100 e quella del secondo sarebbe 120 il costo
intero sarebbe costo(guardia)+120.

Per il for invece la complessità è data dalla sommatoria da i=0 a m-1 di t i.
Dove con m intendiamo la limitazione (i<m), t il costo del corpo, ed i l'iterazione.

Per il while invece la situazione è un po' più complessa:
La sua complessità è uguale alla sommatoria di i=0 ad m di (ti'+ti).
Dove ti' è il costo della guardia all'iterazione i e ti è il costo del corpo di i
ed m è il massimo numero di iterazioni possibili.

La somma geometrica è uguale a: 1+a+a^2+........a^n ==>
a^(n+1)-1/a-1 a>1
DIM:
Sn=1+a+a^2+........a^n==>
Sn-1=a+a^2+........a^n==>
  Sn-1=a(1+a+....a^n-1)
    Sn-1=a(Sn-a^n)==>
      Sn*-a*Sn=1-a^n+1==>
        Sn(-a+1)=1-a^n+1.

Una cosa molto positiva scrivere 'pogrammi' con complessità costante. Un
algoritmo costante non può nemmeno leggere un input in quanto se potesse
dovrebbe avere tempo n. E invece ha tempo c(costante).

Altri tipi di algoritmi positivi sono gli algoritmi logaritmici, che anche in
questo caso non riuscirebbe a leggere input.

Un algoritmo capace di leggere input è un algolitmo lineare, ovvero un algoritmo
del tipo f(n)=cn dove c è una costante non nulla.

Ancora un'altro tipo di algoritmo è l'algoritmo nlog n, che per esempio potrebbe essere il quick sort.
E' non tantissimo lontano da n.

Algoritmo quadratico: f(n)=c n^2 un esempio potrebbe essere un doppio for.
Es: for(int i=0;i<n;i++)
      for(int j=0;j<m;j++)
Algoritmo quadratico --> complessità=n^2.

Es:
for(int i=1;i<=n;i++)
  for(int j=1;j<=i;j++)
E' anch'essa quadrata

Funzione cubica= f(n)=c n^3
for(int i=0;i<n;i++)
  for(int j=0;j<m;j++)
    for(int k=0;k<l;k++)

Quadrati dei primi numeri interi:
somamtoria da i=1 a n di i^2=n(n+1)(2n+1)/6

Dimostriamo per induzione:
sommatoria da i=1 a k di i^2=k(k+1)*2k+1/6

Tesi:
sommatoria da i=1 a k+1 di i^2= sommatoria da i=1 a k di i^2+(k+1)^2 ==>
=>k(k+1)*(2k+1)/6+(k+1)^2

La complessità di questo algoritmo ?

for(int i=1;i<=n;i++) for(int j=1;j<=i;j++) for(int k=1;k<=j;k++) DO SOMETHING
La complessità è uguale alla sommatoria da i=1 a n della sommatoria da j=1 a i
della sommatoria da k=1 a j di t

Che è uguale a t*sommatoria di i=1 a n della sommatoria da j=1 a i di j=>
t*sommatoria da i=1 a n di i(i+1)/2=>t*sommatoria da i=1 a n di
i(i+1)=>t/2(sommatoria da i=1 a ndi i^2+sommatoria da i=1 a n di
i)=>t/2*(n(n+1(2n+1))/6+n(n+1)/2) che è circa uguale a n^3.

Questa è quindi una funzione polinomiale, ovvero la complessità dell'algoritmo è
uguale al valore della potenza più grande

Notazione asintotica con grande o grande omega grande teta

g(n)= GRANDE O(f(n)) se estistono c, n0>0 allora g(n)<=cf(n) per ogni n>n0 (limite superiore)
Assegnamo la complessitò di n ad O(n)

g(n)=GRANDE OMEGA(f(n)) se esistono c,n0>0 un esempio potrebbe essere scansionare
un array inserito da tastiera con una funzione costante, semplicemente non è
possibile crearlo perché dovrebbe fare almeno n passi.
Limite inferiore e si dice grande omega di n

Se i due limiti coincidono si dice GRANDE TETA(n)

Esercizio: calcolare la complessità della potenza di un numero-> O(n)

Posso fare meglio di O(n)?
